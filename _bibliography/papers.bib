---
---


@inproceedings{martinelli2020spiking,
  title={Spiking neural networks trained with backpropagation for low power neuromorphic implementation of voice activity detection},
  author={Martinelli, Flavio and Dellaferrera, Giorgia and Mainar, Pablo and Cernak, Milos},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8544--8548},
  year={2020},
  organization={IEEE},
  bibtex_show={true},
  abbr={ICASSP},
  selected={true},
  website={https://ieeexplore.ieee.org/abstract/document/9053412/},
  doi={10.1109/ICASSP40776.2020.9053412},
  annotation={}, % pop-over message to clarify superscripts (for example)
  code={}, % link to code
  abstract={Recent advances in Voice Activity Detection (VAD) are driven by artificial and Recurrent Neural Networks (RNNs), however, using a VAD system in battery-operated devices requires further power efficiency. This can be achieved by neuromorphic hardware, which enables Spiking Neural Networks (SNNs) to perform inference at very low energy consumption. Spiking networks are characterized by their ability to process information efficiently, in a sparse cascade of binary events in time called spikes. However, a big performance gap separates artificial from spiking networks, mostly due to a lack of powerful SNN training algorithms. To overcome this problem we exploit an SNN model that can be recast into a recurrent network and trained with known deep learning techniques. We describe a training procedure that achieves low spiking activity and apply pruning algorithms to remove up to 85% of the network connections with no performance loss. The model competes with state-of-the-art performance at a fraction of the power consumption comparing to other methods.}
}