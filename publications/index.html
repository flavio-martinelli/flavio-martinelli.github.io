<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Flavio Martinelli </title> <meta name="author" content="Flavio Martinelli"> <meta name="description" content="My publications in reverse chronological order, you can also check my &lt;a href='https://scholar.google.com/citations?user=DabSKBgAAAAJ'&gt;Google Scholar&lt;/a&gt; page."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/brain.svg?5c0fed83d54cb2317e809d2039167702"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://flavio-martinelli.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://flavio-martinelli.github.io/"> <span class="font-weight-bold">Flavio</span> Martinelli </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">My publications in reverse chronological order, you can also check my <a href="https://scholar.google.com/citations?user=DabSKBgAAAAJ" rel="external nofollow noopener" target="_blank">Google Scholar</a> page.</p> </header> <article> <p></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-5 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <a href="https://arxiv.org/" rel="external nofollow noopener" target="_blank">ArXiv</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/channels.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="channels.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="martinelli2025flat" class="col-sm-6"> <div class="title"><a href="https://arxiv.org/abs/2506.14951" rel="external nofollow noopener" target="_blank">Flat Channels to Infinity in Neural Loss Landscapes</a></div> <div class="author"> <em>Flavio Martinelli<sup>*</sup></em>,¬†Alexander Van Meegen<sup>*</sup>,¬†Berfin Simsek,¬†Wulfram Gerstner,¬†and¬†Johanni Brea <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal first author contribution"> </i> </div> <div class="periodical"> <em>arXiv preprint arXiv:2506.14951</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2506.14951" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The loss landscapes of neural networks contain minima and saddle points that may be connected in flat regions or appear in isolation. We identify and characterize a special structure in the loss landscape: channels along which the loss decreases extremely slowly, while the output weights of at least two neurons, a·µ¢ and a‚±º, diverge to ¬±infinity, and their input weight vectors, ùòÑ·µ¢ and ùòÑ‚±º, become equal to each other. At convergence, the two neurons implement a gated linear unit: a·µ¢œÉ(ùòÑ·µ¢‚ãÖx) + a‚±ºœÉ(ùòÑ‚±º‚ãÖx) ‚Üí œÉ(ùòÑ‚ãÖùòÖ) + (ùòÉ‚ãÖùòÖ) œÉ‚Äô(ùòÑ‚ãÖùòÖ). Geometrically, these channels to infinity are asymptotically parallel to symmetry-induced lines of critical points. Gradient flow solvers, and related optimization methods like SGD or ADAM, reach the channels with high probability in diverse regression settings, but without careful inspection they look like flat local minima with finite parameter values. Our characterization provides a comprehensive picture of these quasi-flat regions in terms of gradient dynamics, geometry, and functional interpretation. The emergence of gated linear units at the end of the channels highlights a surprising aspect of the computational capabilities of fully connected layers.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">martinelli2025flat</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Flat Channels to Infinity in Neural Loss Landscapes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Martinelli, Flavio and Van Meegen, Alexander and Simsek, Berfin and Gerstner, Wulfram and Brea, Johanni}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2506.14951}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/arXiv.2506.14951}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-5 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <a href="https://arxiv.org/" rel="external nofollow noopener" target="_blank">ArXiv</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/degeneracy.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="degeneracy.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huang2024measuring" class="col-sm-6"> <div class="title"><a href="https://arxiv.org/abs/2410.03972" rel="external nofollow noopener" target="_blank">Measuring and controlling solution degeneracy across task-trained recurrent neural networks</a></div> <div class="author"> Ann Huang,¬†Satpreet H Singh,¬†<em>Flavio Martinelli</em>,¬†and¬†Kanaka Rajan </div> <div class="periodical"> <em>arXiv preprint arXiv:2410.03972</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2410.03972" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Task-trained recurrent neural networks (RNNs) are widely used in neuroscience and machine learning to model dynamical computations. To gain mechanistic insight into how neural systems solve tasks, prior work often reverse-engineers individual trained networks. However, different RNNs trained on the same task and achieving similar performance can exhibit strikingly different internal solutions-a phenomenon known as solution degeneracy. Here, we develop a unified framework to systematically quantify and control solution degeneracy across three levels: behavior, neural dynamics, and weight space. We apply this framework to 3,400 RNNs trained on four neuroscience-relevant tasks-flip-flop memory, sine wave generation, delayed discrimination, and path integration-while systematically varying task complexity, learning regime, network size, and regularization. We find that higher task complexity and stronger feature learning reduce degeneracy in neural dynamics but increase it in weight space, with mixed effects on behavior. In contrast, larger networks and structural regularization reduce degeneracy at all three levels. These findings empirically validate the Contravariance Principle and provide practical guidance for researchers aiming to tailor RNN solutions-whether to uncover shared neural mechanisms or to model individual variability observed in biological systems. This work provides a principled framework for quantifying and controlling solution degeneracy in task-trained RNNs, offering new tools for building more interpretable and biologically grounded models of neural computation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">huang2024measuring</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Measuring and controlling solution degeneracy across task-trained recurrent neural networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Ann and Singh, Satpreet H and Martinelli, Flavio and Rajan, Kanaka}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2410.03972}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/arXiv.2410.03972}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-5 abbr"> <abbr class="badge rounded w-100" style="background-color:#1e88e5"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/ECstatic.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ECstatic.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="martinelli2023expand" class="col-sm-6"> <div class="title"><a href="https://proceedings.mlr.press/v235/martinelli24a.html" rel="external nofollow noopener" target="_blank">Expand-and-Cluster: Parameter Recovery of Neural Networks</a></div> <div class="author"> <em>Flavio Martinelli</em>,¬†Berfin Simsek,¬†Wulfram Gerstner<sup>*</sup>,¬†and¬†Johanni Brea<sup>*</sup> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal senior author contribution"> </i> </div> <div class="periodical"> <em>In Forty-first International Conference on Machine Learning (ICML)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v235/martinelli24a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/flavio-martinelli/expand-and-cluster" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Can we identify the weights of a neural network by probing its input-output mapping? At first glance, this problem seems to have many solutions because of permutation, overparameterisation and activation function symmetries. Yet, we show that the incoming weight vector of each neuron is identifiable up to sign or scaling, depending on the activation function. Our novel method ‚ÄôExpand-and-Cluster‚Äô can identify layer sizes and weights of a target network for all commonly used activation functions. Expand-and-Cluster consists of two phases: (i) to relax the non-convex optimisation problem, we train multiple overparameterised student networks to best imitate the target function; (ii) to reverse engineer the target network‚Äôs weights, we employ an ad-hoc clustering procedure that reveals the learnt weight vectors shared between students ‚Äì these correspond to the target weight vectors. We demonstrate successful weights and size recovery of trained shallow and deep networks with less than 10% overhead in the layer size and describe an ‚Äôease-of-identifiability‚Äô axis by analysing 150 synthetic problems of variable difficulty.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">martinelli2023expand</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Expand-and-Cluster: Parameter Recovery of Neural Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Martinelli, Flavio and Simsek, Berfin and Gerstner, Wulfram and Brea, Johanni}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Forty-first International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-5 abbr"> <abbr class="badge rounded w-100" style="background-color:#90ee90"> <div>Preprint</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/almond1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="almond1.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="portner2024actor" class="col-sm-6"> <div class="title"><a href="https://www.researchsquare.com/article/rs-3993700/v1" rel="external nofollow noopener" target="_blank">Actor-Critic Networks with Analogue Memristors Mimicking Reward-Based Learning</a></div> <div class="author"> Kevin Portner<sup>*</sup>,¬†Till Zellweger<sup>*</sup>,¬†<em>Flavio Martinelli</em>,¬†Laura B√©gon-Lours,¬†Valeria Bragaglia , and <span class="more-authors" title="click to view 13 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '13 more authors' ? 'Christoph Weilenmann, Daniel Jubin, Donato Falcone, Felix Hermann, Oscar Hrynkevych, Tommaso Stecconi, Antonio La Porta, Ute Drechsler, Antonis Olziersky, Bert Offrein, Wulfram Gerstner, Mathieu Luisier, Alexandros Emboras' : '13 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">13 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal first author contribution"> </i> </div> <div class="periodical"> <em></em> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.researchsquare.com/article/rs-3993700/v1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p>Advancements in memristive devices have given rise to a new generation of specialized hardware for bio-inspired computing. However, the majority of these implementations only draw partial inspiration from the architecture and functionalities of the mammalian brain. Moreover, the use of memristive hardware is typically restricted to specific elements within the learning algorithm, leaving computationally expensive operations to be executed in software. Here, we demonstrate actor-critic temporal difference (TD) learning on analogue memristors, mirroring the principles of reward-based learning in a neural network architecture similar to the one found in biology. Within the learning algorithm, memristors are used as multi-purpose elements: They act as synaptic weights that are trained online, they calculate the weight updates directly in hardware, and they compute the actions for navigating through the environment. Thanks to these features, weight training can take place entirely in-memory, eliminating the need for data movement and enhancing processing speed. Also, our proposed learning scheme possesses self-correction capabilities that effectively counteract noise during the weight update process, which makes it a promising alternative to traditional error mitigation schemes. We test our framework on two classic navigation tasks - the T-maze and the Morris water-maze - using analogue memristors based on the valence change memory (VCM) effect. Our approach represents a first step towards fully in-memory, online, and error-resilient neuromorphic computing engines based on bio-inspired learning schemes.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">portner2024actor</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Actor-Critic Networks with Analogue Memristors Mimicking Reward-Based Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Portner, Kevin and Zellweger, Till and Martinelli, Flavio and B{\'e}gon-Lours, Laura and Bragaglia, Valeria and Weilenmann, Christoph and Jubin, Daniel and Falcone, Donato and Hermann, Felix and Hrynkevych, Oscar and Stecconi, Tommaso and La Porta, Antonio and Drechsler, Ute and Olziersky, Antonis and Offrein, Bert and Gerstner, Wulfram and Luisier, Mathieu and Emboras, Alexandros}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.21203/rs.3.rs-3993700/v1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-5 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <a href="https://arxiv.org/" rel="external nofollow noopener" target="_blank">ArXiv</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/MLPGradientFlow.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MLPGradientFlow.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="brea2023mlpgradientflow" class="col-sm-6"> <div class="title"><a href="https://arxiv.org/abs/2301.10638" rel="external nofollow noopener" target="_blank">Mlpgradientflow: going with the flow of multilayer perceptrons (and finding minima fast and accurately)</a></div> <div class="author"> Johanni Brea,¬†<em>Flavio Martinelli</em>,¬†Berfin ≈ûim≈üek,¬†and¬†Wulfram Gerstner </div> <div class="periodical"> <em>arXiv preprint arXiv:2301.10638</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2301.10638" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/jbrea/MLPGradientFlow.jl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>MLPGradientFlow is a software package to solve numerically the gradient flow differential equation Œ∏ Ãá = ‚àí‚àáL(Œ∏; D), where Œ∏ are the parameters of a multi-layer perceptron, D is some data set, and ‚àáL is the gradient of a loss function. We show numerically that adaptive first- or higher-order integration methods based on Runge-Kutta schemes have better accuracy and convergence speed than gradient descent with the Adam optimizer. However, we find Newton‚Äôs method and approximations like BFGS preferable to find fixed points (local and global minima of L) efficiently and accurately. For small networks and data sets, gradients are usually computed faster than in pytorch and Hessian are computed at least 5√ó faster. Additionally, the package features an integrator for a teacher-student setup with bias-free, two-layer networks trained with standard Gaussian input in the limit of infinite data. The code is accessible at https://github.com/jbrea/MLPGradientFlow.jl.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">brea2023mlpgradientflow</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mlpgradientflow: going with the flow of multilayer perceptrons (and finding minima fast and accurately)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brea, Johanni and Martinelli, Flavio and {\c{S}}im{\c{s}}ek, Berfin and Gerstner, Wulfram}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2301.10638}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/arXiv.2301.10638}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-5 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff985d"> <a href="https://ieeexplore.ieee.org/xpl/conhome/1000002/all-proceedings" rel="external nofollow noopener" target="_blank">ICASSP</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/icassp2020.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icassp2020.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="martinelli2020spiking" class="col-sm-6"> <div class="title"><a href="https://ieeexplore.ieee.org/abstract/document/9053412/" rel="external nofollow noopener" target="_blank">Spiking neural networks trained with backpropagation for low power neuromorphic implementation of voice activity detection</a></div> <div class="author"> <em>Flavio Martinelli</em>,¬†Giorgia Dellaferrera,¬†Pablo Mainar,¬†and¬†Milos Cernak </div> <div class="periodical"> <em>In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9053412/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://codeocean.com/capsule/7317693/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Recent advances in Voice Activity Detection (VAD) are driven by artificial and Recurrent Neural Networks (RNNs), however, using a VAD system in battery-operated devices requires further power efficiency. This can be achieved by neuromorphic hardware, which enables Spiking Neural Networks (SNNs) to perform inference at very low energy consumption. Spiking networks are characterized by their ability to process information efficiently, in a sparse cascade of binary events in time called spikes. However, a big performance gap separates artificial from spiking networks, mostly due to a lack of powerful SNN training algorithms. To overcome this problem we exploit an SNN model that can be recast into a recurrent network and trained with known deep learning techniques. We describe a training procedure that achieves low spiking activity and apply pruning algorithms to remove up to 85% of the network connections with no performance loss. The model competes with state-of-the-art performance at a fraction of the power consumption comparing to other methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">martinelli2020spiking</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Spiking neural networks trained with backpropagation for low power neuromorphic implementation of voice activity detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Martinelli, Flavio and Dellaferrera, Giorgia and Mainar, Pablo and Cernak, Milos}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8544--8548}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP40776.2020.9053412}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-5 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff985d"> <a href="https://ieeexplore.ieee.org/xpl/conhome/1000002/all-proceedings" rel="external nofollow noopener" target="_blank">ICASSP</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/icassp2020b.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icassp2020b.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="dellaferrera2020bin" class="col-sm-6"> <div class="title"><a href="https://ieeexplore.ieee.org/abstract/document/9054761" rel="external nofollow noopener" target="_blank">A bin encoding training of a spiking neural network based voice activity detection</a></div> <div class="author"> Giorgia Dellaferrera,¬†<em>Flavio Martinelli</em>,¬†and¬†Milos Cernak </div> <div class="periodical"> <em>In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9054761" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://codeocean.com/capsule/2406013/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Advances of deep learning for Artificial Neural Networks (ANNs) have led to significant improvements in the performance of digital signal processing systems implemented on digital chips. Although recent progress in low-power chips is remarkable, neuromorphic chips that run Spiking Neural Networks (SNNs) based applications offer an even lower power consumption, as a consequence of the ensuing sparse spikebased coding scheme. In this work, we develop a SNN-based Voice Activity Detection (VAD) system that belongs to the building blocks of any audio and speech processing system. We propose to use the bin encoding, a novel method to convert log mel filterbank bins of single-time frames into spike patterns. We integrate the proposed scheme in a bilayer spiking architecture which was evaluated on the QUT-NOISE-TIMIT corpus. Our approach shows that SNNs enable an ultra low-0power implementation of a VAD classifier that consumes only 3.8 ŒºW, while achieving state-of-the-art performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">dellaferrera2020bin</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A bin encoding training of a spiking neural network based voice activity detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dellaferrera, Giorgia and Martinelli, Flavio and Cernak, Milos}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3207--3211}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP40776.2020.9054761}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Flavio Martinelli. Last updated: October 02, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script data-goatcounter="https://flavio-martinelli.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-home",title:"Home",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"Publications",description:"My publications in reverse chronological order, you can also check my Google Scholar page.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-relu-playground-how-complex-are-the-dynamics-of-one-neuron-learning-another-one",title:"ReLU Playground: how complex are the dynamics of one neuron learning another one?",description:"An interactive playground \u26f9\ufe0f\u200d\u2642\ufe0f",section:"Posts",handler:()=>{window.location.href="/blog/2025/reluplayground/"}},{id:"news-lt-span-style-quot-background-fff9e5-color-ff9800-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-poster-\ufe0f-lt-span-gt-in-frankfurt-for-two-posters-on-lt-a-href-quot-https-abstracts-g-node-org-conference-bc25-abstracts-uuid-53cb5db8-64c8-4172-9145-f929d9801f8c-quot-gt-rnn-solution-degeneracy-lt-a-gt-and-lt-a-href-quot-https-abstracts-g-node-org-conference-bc25-abstracts-uuid-9784d84a-7aed-4f8f-a157-6a97e6de74e6-quot-gt-toy-models-of-identifiability-for-neuroscience-lt-a-gt-at-the-bernstein-conference",title:"&lt;span style=&quot;background: #fff9e5; color: #ff9800; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center&quot;&gt;POSTER \ud83c\udfde\ufe0f&lt;/span&gt; In Frankfurt for two posters on &lt;a href=&quot;https://abstracts.g-node.org/conference/BC25/abstracts#/uuid/53cb5db8-64c8-4172-9145-f929d9801f8c&quot;&gt;RNN solution degeneracy&lt;/a&gt; and &lt;a href=&quot;https://abstracts.g-node.org/conference/BC25/abstracts#/uuid/9784d84a-7aed-4f8f-a157-6a97e6de74e6&quot;&gt;Toy models of identifiability for neuroscience&lt;/a&gt; at the Bernstein conference.",description:"",section:"News"},{id:"news-lt-span-id-quot-paper-label-quot-style-quot-background-fdeaea-color-c62828-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-paper-lt-span-gt-lt-a-href-quot-https-arxiv-org-abs-2410-03972-quot-gt-measuring-and-controlling-solution-degeneracy-across-task-trained-recurrent-neural-networks-lt-a-gt-has-been-accepted-to-lt-a-href-quot-https-neurips-cc-quot-gt-neurips-lt-a-gt-as-spotlight",title:"&lt;span id=&quot;paper-label&quot; style=&quot;background: #fdeaea; color: #c62828; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;PAPER \ud83d\udcdd &lt;/span&gt; &lt;a href=&quot;https://arxiv.org/abs/2410.03972&quot;&gt;Measuring and Controlling Solution Degeneracy across Task-Trained Recurrent Neural Networks&lt;/a&gt; has been accepted to &lt;a href=&quot;https://neurips.cc&quot;&gt;NeurIPS&lt;/a&gt; as spotlight!",description:"",section:"News"},{id:"news-lt-span-id-quot-paper-label-quot-style-quot-background-fdeaea-color-c62828-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-paper-lt-span-gt-lt-a-href-quot-https-arxiv-org-abs-2506-14951-quot-gt-flat-channels-to-infinity-in-neural-loss-landscapes-lt-a-gt-has-been-accepted-to-lt-a-href-quot-https-neurips-cc-quot-gt-neurips-lt-a-gt-for-a-poster",title:"&lt;span id=&quot;paper-label&quot; style=&quot;background: #fdeaea; color: #c62828; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;PAPER \ud83d\udcdd &lt;/span&gt; &lt;a href=&quot;https://arxiv.org/abs/2506.14951&quot;&gt;Flat Channels to Infinity in Neural Loss Landscapes&lt;/a&gt; has been accepted to &lt;a href=&quot;https://neurips.cc&quot;&gt;NeurIPS&lt;/a&gt; for a poster!",description:"",section:"News"},{id:"news-lt-span-style-quot-background-eaf3fb-color-1565c0-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-talk-lt-span-gt-gave-a-talk-about-the-lt-a-href-quot-https-arxiv-org-abs-2506-14951-quot-gt-channels-to-infinity-in-loss-landscapes-lt-a-gt-in-the-lt-a-href-quot-https-app-ploutos-dev-gallery-quot-gt-ploutos-lt-a-gt-platform-lt-a-href-quot-https-app-ploutos-dev-streams-hot-mottled-dog-quot-gt-link-to-video-lt-a-gt",title:"&lt;span style=&quot;background: #eaf3fb; color: #1565c0; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;TALK \ud83c\udfa4&lt;/span&gt; Gave a talk about the &lt;a href=&quot;https://arxiv.org/abs/2506.14951&quot;&gt;channels to infinity in loss landscapes&lt;/a&gt; in the &lt;a href=&quot;https://app.ploutos.dev/gallery&quot;&gt;Ploutos&lt;/a&gt; platform - &lt;a href=&quot;https://app.ploutos.dev/streams/hot-mottled-dog&quot;&gt;link to video&lt;/a&gt;",description:"",section:"News"},{id:"news-currently-in-woods-hole-ma-us-for-the-lt-a-href-quot-https-bmm-mit-edu-quot-gt-mit-brain-minds-and-machines-summer-school-lt-a-gt",title:"\ud83c\udf0e Currently in Woods Hole, MA (US) for the &lt;a href=&quot;https://bmm.mit.edu&quot;&gt;MIT Brain, Minds and Machines summer school&lt;/a&gt;.",description:"",section:"News"},{id:"news-lt-span-id-quot-paper-label-quot-style-quot-background-fdeaea-color-c62828-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-paper-lt-span-gt-we-discover-channels-of-slowly-decreasing-loss-in-network-loss-landscapes-that-lead-to-minima-at-infinite-parameter-norm-in-the-limit-these-solutions-implement-gated-linear-units-using-standard-neurons-these-channels-are-parallel-to-lines-of-saddle-points-generated-by-permutation-symmetries-read-the-paper-lt-a-href-quot-https-arxiv-org-abs-2506-14951-quot-gt-flat-channels-to-infinity-in-neural-loss-landscapes-lt-a-gt",title:"&lt;span id=&quot;paper-label&quot; style=&quot;background: #fdeaea; color: #c62828; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;PAPER \ud83d\udcdd &lt;/span&gt; We discover channels of slowly decreasing loss in network loss landscapes that lead to minima at infinite parameter norm. In the limit, these solutions implement Gated Linear Units using standard neurons. These channels are parallel to lines of saddle points generated by permutation symmetries. Read the paper: &lt;a href=&quot;https://arxiv.org/abs/2506.14951&quot;&gt;Flat Channels to Infinity in Neural Loss Landscapes&lt;/a&gt;.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-fff9e5-color-ff9800-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-poster-\ufe0f-lt-span-gt-presented-a-poster-at-lt-a-href-quot-https-kempnerinstitute-harvard-edu-frontiers-in-neuroai-quot-gt-frontiers-in-neuroai-lt-a-gt-boston-on-optimization-challenges-to-recover-connectivity-from-activity",title:"&lt;span style=&quot;background: #fff9e5; color: #ff9800; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center&quot;&gt;POSTER \ud83c\udfde\ufe0f&lt;/span&gt; Presented a poster at &lt;a href=&quot;https://kempnerinstitute.harvard.edu/frontiers-in-neuroai/&quot;&gt;Frontiers in NeuroAI&lt;/a&gt;, Boston, on optimization challenges to recover connectivity from activity.",description:"",section:"News"},{id:"news-lt-span-id-quot-paper-label-quot-style-quot-background-fdeaea-color-c62828-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-paper-lt-span-gt-how-degenerate-is-the-solution-space-of-identical-rnns-trained-on-the-same-task-check-out-our-new-paper-on-lt-a-href-quot-https-arxiv-org-abs-2410-03972-quot-gt-measuring-and-controlling-degeneracy-of-rnns-lt-a-gt-fun-collaboration-with-the-rajan-lab",title:"&lt;span id=&quot;paper-label&quot; style=&quot;background: #fdeaea; color: #c62828; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;PAPER \ud83d\udcdd &lt;/span&gt; How degenerate is the solution space of identical RNNs trained on the same task? Check out our new paper on &lt;a href=&quot;https://arxiv.org/abs/2410.03972&quot;&gt;measuring and controlling degeneracy of RNNs&lt;/a&gt;. Fun collaboration with the Rajan Lab.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-fff9e5-color-ff9800-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-poster-\ufe0f-lt-span-gt-presented-a-poster-at-kempner-institute-s-lt-a-href-quot-https-kempnerinstitute-harvard-edu-events-spring-into-science-quot-gt-spring-into-science-lt-a-gt-meeting",title:"&lt;span style=&quot;background: #fff9e5; color: #ff9800; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center&quot;&gt;POSTER \ud83c\udfde\ufe0f&lt;/span&gt; Presented a poster at Kempner Institute\u2019s &lt;a href=&quot;https://kempnerinstitute.harvard.edu/events/spring-into-science/&quot;&gt;Spring Into Science&lt;/a&gt; meeting.",description:"",section:"News"},{id:"news-i-am-currently-based-in-boston-for-a-4-months-visit-in-lt-a-href-quot-https-www-rajanlab-com-quot-gt-kanaka-rajan-s-lab-lt-a-gt-reach-out-if-you-want-to-have-a-chat",title:"\ud83c\udf0e I am currently based in Boston for a 4 months visit in &lt;a href=&quot;https://www.rajanlab.com&quot;&gt;Kanaka Rajan\u2019s lab&lt;/a&gt;. Reach out if you want to have a chat!",description:"",section:"News"},{id:"news-lt-span-style-quot-background-eaf3fb-color-1565c0-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-talk-lt-span-gt-i-gave-a-talk-on-lt-a-href-quot-https-proceedings-mlr-press-v235-martinelli24a-html-quot-gt-expand-and-cluster-lt-a-gt-for-the-lt-a-href-quot-https-sites-google-com-view-efficientml-quot-gt-efficientml-lt-a-gt-reading-group-lt-a-href-quot-https-www-youtube-com-watch-v-fqkom4rkyx8-quot-gt-link-to-video-lt-a-gt",title:"&lt;span style=&quot;background: #eaf3fb; color: #1565c0; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;TALK \ud83c\udfa4&lt;/span&gt; I gave a talk on &lt;a href=&quot;https://proceedings.mlr.press/v235/martinelli24a.html&quot;&gt;Expand-and-Cluster&lt;/a&gt; for the &lt;a href=&quot;https://sites.google.com/view/efficientml&quot;&gt;EfficientML&lt;/a&gt; reading group \u2013 &lt;a href=&quot;https://www.youtube.com/watch?v=fqKoM4rkYX8&quot;&gt;link to video&lt;/a&gt;.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-eaf3fb-color-1565c0-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-talk-lt-span-gt-lt-span-style-quot-background-fff9e5-color-ff9800-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-poster-\ufe0f-lt-span-gt-in-vienna-for-icml-24-and-a-visit-to-lt-a-href-quot-https-vogelslab-org-quot-gt-tim-vogel-s-lab-lt-a-gt-in-ist-austria",title:"&lt;span style=&quot;background: #eaf3fb; color: #1565c0; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;TALK \ud83c\udfa4&lt;/span&gt; &lt;span style=&quot;background: #fff9e5; color: #ff9800; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center&quot;&gt;POSTER \ud83c\udfde\ufe0f&lt;/span&gt; In Vienna for ICML \u201824 and a visit to &lt;a href=&quot;https://vogelslab.org&quot;&gt;Tim Vogel\u2019s lab&lt;/a&gt; in IST, Austria.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-fff9e5-color-ff9800-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-poster-\ufe0f-lt-span-gt-in-trieste-for-the-lt-a-href-quot-https-www-itsoc-org-event-youth-high-dimensions-2024-quot-gt-youth-in-high-dimensions-lt-a-gt-meeting",title:"&lt;span style=&quot;background: #fff9e5; color: #ff9800; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center&quot;&gt;POSTER \ud83c\udfde\ufe0f&lt;/span&gt; In Trieste for the &lt;a href=&quot;https://www.itsoc.org/event/youth-high-dimensions-2024&quot;&gt;Youth in High Dimensions&lt;/a&gt; meeting.",description:"",section:"News"},{id:"news-lt-span-id-quot-paper-label-quot-style-quot-background-fdeaea-color-c62828-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-paper-lt-span-gt-lt-a-href-quot-https-proceedings-mlr-press-v235-martinelli24a-html-quot-gt-expand-and-cluster-lt-a-gt-is-accepted-to-icml-2024-lt-br-gt-lt-br-gt-we-identify-the-weights-of-a-neural-network-from-simple-input-output-queries-lt-br-gt-\ufe0f-symmetries-and-overparameterised-loss-landscapes-are-heavily-involved",title:"&lt;span id=&quot;paper-label&quot; style=&quot;background: #fdeaea; color: #c62828; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;PAPER \ud83d\udcdd &lt;/span&gt; &lt;a href=&quot;https://proceedings.mlr.press/v235/martinelli24a.html&quot;&gt;Expand-and-Cluster&lt;/a&gt; is accepted to ICML 2024! &lt;br /&gt; &lt;br /&gt; \ud83d\udd0d We identify the weights of a neural network from simple input-output queries. &lt;br /&gt; \u26a0\ufe0f Symmetries and overparameterised loss landscapes are heavily involved.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-eaf3fb-color-1565c0-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-talk-lt-span-gt-gave-a-talk-and-visited-the-lt-a-href-quot-https-www-mackelab-org-quot-gt-laboratory-of-jakob-macke-lt-a-gt-at-the-t\xfcbingen-ai-center-germany",title:"&lt;span style=&quot;background: #eaf3fb; color: #1565c0; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;TALK \ud83c\udfa4&lt;/span&gt; Gave a talk and visited the &lt;a href=&quot;https://www.mackelab.org&quot;&gt;laboratory of Jakob Macke&lt;/a&gt; at the T\xfcbingen AI Center, Germany.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-eaf3fb-color-1565c0-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-talk-lt-span-gt-gave-a-talk-at-the-annual-lt-a-href-quot-https-www-swisscompneuro-org-quot-gt-swiss-computational-neuroscience-lt-a-gt-meeting",title:"&lt;span style=&quot;background: #eaf3fb; color: #1565c0; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;TALK \ud83c\udfa4&lt;/span&gt; Gave a talk at the annual &lt;a href=&quot;https://www.swisscompneuro.org&quot;&gt;Swiss Computational Neuroscience&lt;/a&gt; meeting.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-fff9e5-color-ff9800-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-poster-\ufe0f-lt-span-gt-in-berlin-for-a-lt-a-href-quot-https-abstracts-g-node-org-conference-bc23-abstracts-uuid-4b6c7f58-1209-4c8c-811f-adb43289170c-quot-gt-poster-lt-a-gt-at-the-bernstein-conference",title:"&lt;span style=&quot;background: #fff9e5; color: #ff9800; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center&quot;&gt;POSTER \ud83c\udfde\ufe0f&lt;/span&gt; In Berlin for a &lt;a href=&quot;https://abstracts.g-node.org/conference/BC23/abstracts#/uuid/4b6c7f58-1209-4c8c-811f-adb43289170c&quot;&gt;poster&lt;/a&gt; at the Bernstein conference.",description:"",section:"News"},{id:"news-lt-span-style-quot-background-eaf3fb-color-1565c0-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-talk-lt-span-gt-best-presentation-award-at-the-lt-a-href-quot-https-wp-unil-ch-lemanicneuroscience-annual-retreat-previous-retreats-quot-gt-neuroleman-meeting-lt-a-gt-\ufe0f",title:"&lt;span style=&quot;background: #eaf3fb; color: #1565c0; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;TALK \ud83c\udfa4&lt;/span&gt; Best presentation award at the &lt;a href=&quot;https://wp.unil.ch/lemanicneuroscience/annual-retreat/previous-retreats/&quot;&gt;NeuroLeman meeting&lt;/a&gt; \ud83c\udf96\ufe0f",description:"",section:"News"},{id:"news-lt-span-style-quot-background-eaf3fb-color-1565c0-padding-2px-6px-border-radius-6px-font-size-110-display-inline-block-width-110px-text-align-center-quot-gt-talk-lt-span-gt-gave-a-talk-and-visited-the-group-of-lt-a-href-quot-https-as-inf-ethz-ch-index-html-quot-gt-angelika-steger-and-joao-sacramento-lt-a-gt-in-eth-z\xfcrich",title:"&lt;span style=&quot;background: #eaf3fb; color: #1565c0; padding: 2px 6px; border-radius: 6px; font-size: 110%; display: inline-block; width: 110px; text-align: center;&quot;&gt;TALK \ud83c\udfa4&lt;/span&gt; Gave a talk and visited the group of &lt;a href=&quot;https://as.inf.ethz.ch/index.html&quot;&gt;Angelika Steger and Joao Sacramento&lt;/a&gt; in ETH, Z\xfcrich.",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%66%6C%61%76%69%6F.%6D%61%72%74%69%6E%65%6C%6C%69@%65%70%66%6C.%63%68","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=DabSKBgAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/flavio-martinelli","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/flavio-martinelli-9b6695106","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/FlaviohMar","_blank")}},{id:"socials-work",title:"Work",section:"Socials",handler:()=>{window.open("https://people.epfl.ch/flavio.martinelli","_blank")}},{id:"socials-bluesky",title:"Bluesky",section:"Socials",handler:()=>{window.open("https://bsky.app/profile/https://bsky.app/profile/flavioh.bsky.social","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>